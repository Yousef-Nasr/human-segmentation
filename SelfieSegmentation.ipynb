{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSLGqZ9MIvG5",
        "outputId": "cd44204e-7280-4917-cdfc-d50326cd0407"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pcanbxCIteL"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "local_zip = '/content/drive/MyDrive/human-img-seg.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('dataset')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXS-m3iA5nG4"
      },
      "source": [
        "# Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09OnxZbMIplw"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tqdm import tqdm\n",
        "import tensorflow.data as tfd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from typing import List, Tuple, Union"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYQ-Fyih52Ng"
      },
      "source": [
        "# Load and prepare Dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hutDWmgIpl1"
      },
      "outputs": [],
      "source": [
        "image_train_dir = \"/content/dataset/training/sample\"\n",
        "mask_train_dir = \"/content/dataset/training/mask\"\n",
        "\n",
        "train_img_paths = sorted(\n",
        "    [os.path.join(image_train_dir, fname)\n",
        "     for fname in os.listdir(image_train_dir)\n",
        "     if fname.endswith(\".png\")])\n",
        "train_mask_paths = sorted(\n",
        "    [os.path.join(mask_train_dir, fname)\n",
        "     for fname in os.listdir(mask_train_dir)\n",
        "     if fname.endswith(\".png\") and not fname.startswith(\".\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mziFH1XwIpl3"
      },
      "outputs": [],
      "source": [
        "image_test_dir = \"/content/dataset/testing/sample\"\n",
        "mask_test_dir = \"/content/dataset/testing/mask\"\n",
        "\n",
        "test_img_paths = sorted(\n",
        "    [os.path.join(image_test_dir, fname)\n",
        "     for fname in os.listdir(image_test_dir)\n",
        "     if fname.endswith(\".png\")])\n",
        "test_mask_paths = sorted(\n",
        "    [os.path.join(mask_test_dir, fname)\n",
        "     for fname in os.listdir(mask_test_dir)\n",
        "     if fname.endswith(\".png\") and not fname.startswith(\".\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOfGtwqXIpl4"
      },
      "outputs": [],
      "source": [
        "N_IMAGE_CHANNELS = 3\n",
        "N_MASK_CHANNELS = 1\n",
        "\n",
        "IMAGE_WIDTH = 256\n",
        "IMAGE_HEIGHT = 256\n",
        "\n",
        "IMAGE_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT, N_IMAGE_CHANNELS)\n",
        "MASK_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT, N_MASK_CHANNELS)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "OUTPUT_CHANNELS = 1\n",
        "\n",
        "EPOCHS = 10\n",
        "FILTERS = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obcHDo9gIpl5"
      },
      "outputs": [],
      "source": [
        "def load_image_and_mask(image_path, mask_path):\n",
        "    \n",
        "    '''\n",
        "    This function takes the file paths of an image and mask as input function converts the image and mask tensors to the float32 data type and returns.\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    # Read the images\n",
        "    image = tf.io.read_file(filename = image_path)\n",
        "    mask  = tf.io.read_file(filename = mask_path)\n",
        "    \n",
        "    # Decode the images\n",
        "    image = tf.image.decode_jpeg(contents = image, channels = N_IMAGE_CHANNELS)\n",
        "    mask  = tf.image.decode_jpeg(contents = mask,  channels = N_MASK_CHANNELS)\n",
        "    \n",
        "    # Convert the image to a Tensor\n",
        "    image = tf.image.convert_image_dtype(image = image, dtype = tf.float32)\n",
        "    mask  = tf.image.convert_image_dtype(image = mask, dtype = tf.float32)\n",
        "    \n",
        "    # Resize the image to the desired dimensions\n",
        "    image = tf.image.resize(images = image, size = (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
        "    mask  = tf.image.resize(images = mask, size = (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
        "    \n",
        "    # Normalize the image\n",
        "    image = tf.clip_by_value(image, clip_value_min = 0.0, clip_value_max = 1.0)\n",
        "    mask  = tf.clip_by_value(mask, clip_value_min = 0.0, clip_value_max = 1.0)\n",
        "    \n",
        "    # Final conversion\n",
        "    image = tf.cast(image, dtype = tf.float32)\n",
        "    mask  = tf.cast(mask,  dtype = tf.float32)\n",
        "    \n",
        "    return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gy1qsM2fIpl7"
      },
      "outputs": [],
      "source": [
        "def load_dataset(\n",
        "    image_paths, mask_paths, batch_size=BATCH_SIZE, shuffle=True, \n",
        "    buffer_size=1000, n_repeat=1) :\n",
        "    '''\n",
        "    This function loads the image and mask data from the file paths and creates a tensorflow dataset. \n",
        "    '''\n",
        "    \n",
        "    # Create array to storing the data.\n",
        "    images = np.empty(shape=(len(image_paths), *IMAGE_SIZE), dtype=np.float32)\n",
        "    masks  = np.empty(shape=(len(mask_paths), *MASK_SIZE),  dtype=np.float32)\n",
        "    \n",
        "    # Iterate over the data.\n",
        "    index = 0\n",
        "    for image_path, mask_path in tqdm(zip(image_paths, mask_paths), desc='Loading'):\n",
        "        \n",
        "        # Load the image and the mask.\n",
        "        image, mask = load_image_and_mask(image_path = image_path, mask_path = mask_path)\n",
        "        \n",
        "        # Store the image and the mask.\n",
        "        images[index] = image\n",
        "        masks[index]  = mask\n",
        "        \n",
        "        index += 1\n",
        "    \n",
        "    # Create a Tensorflow data.\n",
        "    data_set = tfd.Dataset.from_tensor_slices((images, masks)).repeat(n_repeat)\n",
        "    \n",
        "    # Shuffle the data set.\n",
        "    if shuffle:\n",
        "        data_set = data_set.shuffle(buffer_size)\n",
        "    \n",
        "    # Convert data into batches\n",
        "    data_set = data_set.batch(batch_size, drop_remainder=True).prefetch(tfd.AUTOTUNE)\n",
        "    \n",
        "    # Return the data\n",
        "    return data_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyhEZQlgIpl9",
        "outputId": "712ad992-e344-42b0-ab3f-da92f3572c0c"
      },
      "outputs": [],
      "source": [
        "# Training and Testing Data\n",
        "train_ds = load_dataset(\n",
        "    image_paths = train_img_paths,\n",
        "    mask_paths = train_mask_paths,\n",
        "    shuffle = True,\n",
        "    n_repeat=1,\n",
        ")\n",
        "test_ds = load_dataset(\n",
        "    image_paths = test_img_paths,\n",
        "    mask_paths = test_mask_paths,\n",
        "    shuffle = True,\n",
        "    n_repeat=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYcqof4uIpl_",
        "outputId": "21f6f0c4-c6a4-4edc-9f5e-da6a82881b1c"
      },
      "outputs": [],
      "source": [
        "print(f\"{' '*30}Training Data Size : {train_ds.cardinality().numpy() * BATCH_SIZE}\")\n",
        "print(f\"{' '*30}Testing Data Size  : {test_ds.cardinality().numpy() * BATCH_SIZE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BX712AeJIpmA"
      },
      "outputs": [],
      "source": [
        "# Split Data \n",
        "full_train_size = train_ds.cardinality().numpy()\n",
        "\n",
        "train_val_split = 0.1\n",
        "valid_size = int(full_train_size * train_val_split)\n",
        "train_size = full_train_size - valid_size\n",
        "\n",
        "training_ds = train_ds.take(train_size)\n",
        "valid_ds = train_ds.skip(train_size).take(valid_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1qyhst-IpmB",
        "outputId": "e0e98b05-b8e8-41af-b0ed-495503620e94"
      },
      "outputs": [],
      "source": [
        "print(f\"{' '*30}Training Data Size   : {training_ds.cardinality().numpy() * BATCH_SIZE}\")\n",
        "print(f\"{' '*30}Validation Data Size : {valid_ds.cardinality().numpy() * BATCH_SIZE}\")\n",
        "print(f\"{' '*30}Testing Data Size    : {test_ds.cardinality().numpy() * BATCH_SIZE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "I2gmMhUIIpmC",
        "outputId": "aa201fa7-0c07-4305-9000-eab9817d0957"
      },
      "outputs": [],
      "source": [
        "def show_images_and_masks(data, n_images=10, FIGSIZE=(25, 5), model=None):\n",
        "    '''\n",
        "    this function is for show the image and the mask and the mask overlay on the image,\n",
        "    when adding model it can show the predicted mask and overlay the predicted mask on the image\n",
        "    \n",
        "    '''\n",
        "    if model is None:\n",
        "        n_cols = 3\n",
        "    else:\n",
        "        n_cols = 5\n",
        "    \n",
        "    # take some data\n",
        "    images, masks = next(iter(data))\n",
        "    \n",
        "    # Iterate over the data\n",
        "    for n in range(n_images):\n",
        "        \n",
        "        plt.figure(figsize=FIGSIZE)\n",
        "        \n",
        "        # Plot the image\n",
        "        plt.subplot(1, n_cols, 1)\n",
        "        plt.title(\"Original Image\")\n",
        "        plt.imshow(images[n])\n",
        "        plt.axis('off')\n",
        "        \n",
        "        # Plot the Mask\n",
        "        plt.subplot(1, n_cols, 2)\n",
        "        plt.title(\"Original Mask\")\n",
        "        plt.imshow(masks[n], cmap='gray')\n",
        "        plt.axis('off')\n",
        "        \n",
        "        # Plot image and mask overlay\n",
        "        plt.subplot(1, n_cols, 3)\n",
        "        plt.title('Image and Mask overlay')\n",
        "        plt.imshow(masks[n], alpha=0.8, cmap='binary_r')\n",
        "        plt.imshow(images[n], alpha=0.5)\n",
        "        plt.axis('off')\n",
        "        \n",
        "        # Model predictions\n",
        "        if model is not None:\n",
        "            pred_mask = model.predict(tf.expand_dims(images[n], axis=0))[0]\n",
        "            plt.subplot(1, n_cols, 4)\n",
        "            plt.title('Predicted Mask')\n",
        "            plt.imshow(pred_mask, cmap='gray')\n",
        "            plt.axis('off')\n",
        "            \n",
        "            plt.subplot(1, n_cols, 5)\n",
        "            plt.title('Predicted Mask Overlay')\n",
        "            plt.imshow(pred_mask*images[n], alpha=1, cmap='binary_r')\n",
        "            plt.axis('off')\n",
        "    \n",
        "        # Show final plot\n",
        "        plt.show()\n",
        "\n",
        "show_images_and_masks(data=train_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY6rhsWZs8M-"
      },
      "source": [
        "# **UNET** architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcKr8xLZ6SJD"
      },
      "source": [
        "![UNET architecture](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png \"UNET architecture\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrOSp1Q1-J3A"
      },
      "source": [
        "### UNET-Encoder block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GpZRmcwtArK"
      },
      "outputs": [],
      "source": [
        "# Encoder\n",
        "\n",
        "def encoder_block(input_tensor, n_filters, kernal_size= 3, max_pool= True,rate= 0.2):\n",
        "    x = input_tensor\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(filters=n_filters,\n",
        "            kernel_size=kernal_size,\n",
        "            strides=1,\n",
        "            padding='same',\n",
        "            activation='relu',\n",
        "            kernel_initializer='he_normal')(x)\n",
        "    x = layers.Conv2D(filters=n_filters,\n",
        "        kernel_size=kernal_size,\n",
        "        strides=1,\n",
        "        padding='same',\n",
        "        activation='relu',\n",
        "        kernel_initializer='he_normal')(x)\n",
        "    if max_pool:\n",
        "        p = layers.Dropout(rate)(x)\n",
        "        p = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(p)\n",
        "        return x, p\n",
        "    else: \n",
        "        x = layers.Dropout(rate)(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def encoder(inputs):\n",
        "    f1, p1 = encoder_block(inputs, n_filters=FILTERS, rate=0.1)\n",
        "    f2, p2 = encoder_block(p1, n_filters=2*FILTERS, rate=0.1)\n",
        "    f3, p3 = encoder_block(p2, n_filters=4*FILTERS, rate=0.2)\n",
        "    f4, p4 = encoder_block(p3, n_filters=8*FILTERS, rate=0.3)\n",
        "\n",
        "    return p4, (f1, f2, f3, f4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxJKbtp7-RFU"
      },
      "source": [
        "### UNET-Decoder block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7wWb4VotF32"
      },
      "outputs": [],
      "source": [
        "def decoder_block(inputs, conv_output, filters, rate=0.2):\n",
        "    u = layers.Conv2DTranspose(\n",
        "        filters = filters,\n",
        "        kernel_size = 3,\n",
        "        strides = 2,\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = 'he_normal')(inputs)\n",
        "    c = layers.concatenate([u, conv_output])\n",
        "    c = layers.BatchNormalization()(c)\n",
        "    c = encoder_block(c, n_filters= filters, rate= rate, max_pool = False)\n",
        "    \n",
        "    return c\n",
        "\n",
        "def decoder(inputs ,convs, output_channels):\n",
        "    f1, f2, f3, f4 = convs\n",
        "\n",
        "    c6 = decoder_block(inputs, f4, rate=0.2, filters=8*FILTERS)\n",
        "    c7 = decoder_block(c6, f3, rate =0.2, filters=4*FILTERS)\n",
        "    c8 = decoder_block(c7, f2, rate= 0.1, filters=2*FILTERS)\n",
        "    c9 = decoder_block(c8, f1, rate= 0.1,  filters=FILTERS)\n",
        "\n",
        "    outputs = layers.Conv2D(output_channels,\n",
        "                            kernel_size= 1,\n",
        "                            strides=1,\n",
        "                            padding='same',\n",
        "                            activation='sigmoid')(c9)\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcxqZZ7q-wpZ"
      },
      "source": [
        "### Combine encoder block and decoder block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NxWE-AVtIPO",
        "outputId": "14bd8a80-b81e-4667-e9d0-ac8631ebf4e2"
      },
      "outputs": [],
      "source": [
        "inputs = layers.Input(shape=IMAGE_SIZE)\n",
        "\n",
        "encoder_output, convs = encoder(inputs)\n",
        "\n",
        "bottle_neck = encoder_block(encoder_output, n_filters=FILTERS*16, max_pool=False, rate=0.3)\n",
        "\n",
        "decoder_output = decoder(bottle_neck, convs, OUTPUT_CHANNELS)\n",
        "\n",
        "model = keras.Model(\n",
        "    inputs= inputs,\n",
        "    outputs= decoder_output\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uFaL--QQuREH",
        "outputId": "ada53f32-9048-4172-df9c-7cbbf305c03a"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(model = model, to_file = \"Unet2Model.png\", dpi = 96, show_shapes=True,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G8JZBr7sp_3"
      },
      "source": [
        "# Custom callback "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xkv04PyNIpmK"
      },
      "outputs": [],
      "source": [
        "class ShowProgress(callbacks.Callback):\n",
        "    \"\"\"\n",
        "    A callback that displays the original image, the original mask, \n",
        "    the predicted mask  and the image and predicted mask overlay on \n",
        "    sample image after each epoch of training.\n",
        "    \"\"\"\n",
        "    def __init__(self, data, cmap = 'gray', num_images = 1, file_format = 'png', **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "      \n",
        "        self.data = data\n",
        "        self.cmap = cmap\n",
        "        self.num_images = num_images\n",
        "        self.file_format = file_format\n",
        "    \n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "\n",
        "        # Plotting configuration\n",
        "        plt.figure(figsize=(25, 8 * self.num_images))\n",
        "        \n",
        "        for i in range(self.num_images):\n",
        "            # Get Data \n",
        "            images, masks = next(iter(self.data))\n",
        "            images = images.numpy()\n",
        "            masks = masks.numpy()\n",
        "            \n",
        "            # Select image\n",
        "            index = np.random.randint(len(images))\n",
        "            image, mask = images[index], masks[index]\n",
        "\n",
        "            # Make Prediction\n",
        "            pred_mask = self.model.predict(np.expand_dims(image, axis=0))[0]\n",
        "            mask1 = pred_mask.copy()\n",
        "            masked_pred_img = image * mask1\n",
        "            # Show Image\n",
        "            plt.subplot(1, 4, 1)\n",
        "            plt.title(\"Original Image\")\n",
        "            plt.imshow(image)\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Show Mask\n",
        "            plt.subplot(1, 4, 2)\n",
        "            plt.title(\"Original Mask\")\n",
        "            plt.imshow(mask, cmap=self.cmap)\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Show Model Pred\n",
        "            plt.subplot(1, 4, 3)\n",
        "            plt.title(\"Predicted Mask\")\n",
        "            plt.imshow(pred_mask, cmap=self.cmap)\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Show pred and image overlay\n",
        "            plt.subplot(1, 4, 4)\n",
        "            plt.title(\"masked photo\")\n",
        "            plt.imshow(masked_pred_img)\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Show Final plot\n",
        "            plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehsb_zeqIpmM"
      },
      "outputs": [],
      "source": [
        "CALLBACKS = [\n",
        "    # callbacks.EarlyStopping(\n",
        "    #     patience = 10, \n",
        "    #     monitor=\"val_loss\",\n",
        "    #     restore_best_weights = True),\n",
        "    ShowProgress(\n",
        "        data = valid_ds\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFj4rnbI7Sx3"
      },
      "source": [
        "# Custom evaluation metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFSYK0jZ7qGh"
      },
      "source": [
        "The Dice coefficient is a measure of the similarity between two samples. In the context of image segmentation, it is used to evaluate the performance of a segmentation algorithm by measuring the overlap between the predicted segmentation and the ground truth segmentation.\n",
        "\n",
        "The Dice coefficient is calculated as follows:\n",
        "\n",
        "`dice_coeff = 2 * |X ∩ Y| / (|X| + |Y|)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_A0nwxwxIpmN"
      },
      "outputs": [],
      "source": [
        "def dice_coeff(y_true, y_pred, smooth=1.0):\n",
        "    \n",
        "    \"\"\"\n",
        "    calc the Dice coefficient between predicted and true masks.\n",
        "\n",
        "    \"\"\"\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
        "    union = tf.reduce_sum(y_true, axis=[1, 2, 3]) + tf.reduce_sum(y_pred, axis=[1, 2, 3])\n",
        "    dice = tf.reduce_mean((2.0 * intersection + smooth) / (union + smooth), axis=0)\n",
        "\n",
        "    return tf.cast(dice, tf.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmEQ0bs62ZP_"
      },
      "outputs": [],
      "source": [
        "# Register the custom metric\n",
        "custom_objects = {'dice_coeff': dice_coeff}\n",
        "tf.keras.utils.get_custom_objects().update(custom_objects)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_b-YVcx8pql"
      },
      "source": [
        "# Compile and train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNVdkM06IpmN"
      },
      "outputs": [],
      "source": [
        "# Mean Intersection Over Union\n",
        "mean_iou = metrics.MeanIoU(num_classes=2, name=\"MeanIoU\")\n",
        "# optimizer\n",
        "optimizer = optimizers.Adam()\n",
        "\n",
        "# Compile Model\n",
        "model.compile(\n",
        "    loss = 'binary_crossentropy',\n",
        "    optimizer = optimizer,\n",
        "    metrics = [\n",
        "        'accuracy',\n",
        "        mean_iou,\n",
        "        dice_coeff\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Oo9WUpROIpmO",
        "outputId": "b8a1d3a4-bdf8-44f0-e854-bf1c5876e07e"
      },
      "outputs": [],
      "source": [
        "# Model Training\n",
        "unet_model_history = model.fit(\n",
        "    training_ds,\n",
        "    validation_data = valid_ds,\n",
        "    epochs = EPOCHS,\n",
        "    callbacks = CALLBACKS,\n",
        "    batch_size = BATCH_SIZE,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAY1pS-fQ5TZ"
      },
      "outputs": [],
      "source": [
        "model.save('FinalModel.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjgiIaTJSlaJ"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/FinalModel.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5zKhCHd838D"
      },
      "source": [
        "# Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaXgw0SQS943"
      },
      "outputs": [],
      "source": [
        "history = unet_model_history.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "Oe0m0oXYTAoQ",
        "outputId": "36872689-7dd5-4423-ecf7-2f7c43a7459e"
      },
      "outputs": [],
      "source": [
        "# show model losses and accuracy\n",
        "plt.figure(figsize=(25,10))\n",
        "\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(history['loss'], label='Training Loss')\n",
        "plt.plot(history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Binary Croscentropy Loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(history['accuracy'], label='accuracy')\n",
        "plt.plot(history['val_accuracy'], label='Validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(2,2,3)\n",
        "plt.plot(history['MeanIoU'], label='MeanIoU')\n",
        "plt.plot(history['val_MeanIoU'], label='Validation MeanIoU')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MeanIoU Score')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(2,2,4)\n",
        "plt.plot(history['dice_coeff'], label='Dice Coeff')\n",
        "plt.plot(history['val_dice_coeff'], label='Validation Dice Coeff')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Dice Coeff Score')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nms_LQpj15ft",
        "outputId": "0ff8330d-cbba-49a4-f491-b6f96c5c8447"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test data\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[dice_coeff])\n",
        "\n",
        "loss, dice_coeff = model.evaluate(test_ds)\n",
        "\n",
        "# Print the results\n",
        "print('Test loss:', loss)\n",
        "print('Test dice_coeff:', dice_coeff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "siSUEOpnTMBR",
        "outputId": "68bef44b-0195-4a76-e5c5-595830f7e50b"
      },
      "outputs": [],
      "source": [
        "show_images_and_masks(data=training_ds, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uXp0cdDcTmom",
        "outputId": "e741e676-b4c3-4723-cc5f-86acea76eb6b"
      },
      "outputs": [],
      "source": [
        "show_images_and_masks(data=test_ds, model=model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE-h4tfS87Jb"
      },
      "source": [
        "# Make some predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67yy9BLsarKM"
      },
      "outputs": [],
      "source": [
        "# try model predictions\n",
        "from PIL import Image\n",
        "from urllib.request import urlopen\n",
        "\n",
        "def load_img(path):\n",
        "    img = Image.open(urlopen(path))\n",
        "    img = img.resize((256, 256))\n",
        "    img = np.asarray(img) / 255.0\n",
        "    return img\n",
        "def pre_image(path):\n",
        "    img = Image.open(urlopen(path))\n",
        "    img = img.resize((256, 256))\n",
        "    img = np.asarray(img) / 255.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFbot2j7ontW"
      },
      "outputs": [],
      "source": [
        "test_image = 'https://assets.vogue.in/photos/604cd4ac6a9323b082cc4e0f/1:1/w_686,h_686,c_limit/selfies.jpg'\n",
        "real_img = load_img(test_image)\n",
        "procces_img = pre_image(test_image)\n",
        "predicted_mask = model.predict(procces_img)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "7g6bR7cFlVTV",
        "outputId": "8db9f4df-64a5-49ec-94fa-208fd7539373"
      },
      "outputs": [],
      "source": [
        "# show result\n",
        "fig, axs = plt.subplots(ncols=3, figsize=(25, 8))\n",
        "axs[0].imshow(real_img)\n",
        "axs[0].set_title('Test Image')\n",
        "axs[1].imshow(predicted_mask, cmap='gray')\n",
        "axs[1].set_title('Predicted Mask')\n",
        "axs[2].imshow(predicted_mask * real_img)\n",
        "axs[2].set_title('Masked Image')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kucrmxsR9Crr"
      },
      "source": [
        "# END\n",
        "**Git repo:** https://github.com/Yousef-Nasr/human-segmentation <br>\n",
        "**Live demo:**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
